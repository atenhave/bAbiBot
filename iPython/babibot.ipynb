{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from slackclient import SlackClient \n",
    "from keras.models import load_model\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize the text\n",
    "# Convert Subtext, Questions to Vector Form\n",
    "def vectorize_ques(data, word_id, test_max_length, ques_max_length):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    for subtext, question in data:\n",
    "        x = [word_id[w] for w in subtext]\n",
    "        xq = [word_id[w] for w in question]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "    return (pad_sequences(X, maxlen=test_max_length),\n",
    "            pad_sequences(Xq, maxlen=ques_max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "max_story_len = 156\n",
    "max_query_len = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<@U5WBCMR88>\n"
     ]
    }
   ],
   "source": [
    "# starterbot's ID as an environment variable\n",
    "BOT_ID = os.environ.get(\"BOT_ID\")\n",
    "\n",
    "# constants\n",
    "AT_BOT = \"<@\" + BOT_ID + \">\"\n",
    "print(AT_BOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('model.h5')\n",
    "text = []\n",
    "question = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate Slack & Twilio clients\n",
    "slack_client = SlackClient(os.environ.get('SLACK_BOT_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def handle_command(command, channel):\n",
    "    print(\"command: \" + command)\n",
    "    \"\"\"\n",
    "        Receives commands directed at the bot and determines if they\n",
    "        are valid commands. If so, then acts on the commands. If not,\n",
    "        returns back what it needs for clarification.\n",
    "    \"\"\"\n",
    "    if command == 'start' or command == \"new story\":\n",
    "        text.clear()\n",
    "        response = \"Enter story\"\n",
    "        slack_client.api_call(\"chat.postMessage\", channel=channel, text=response, as_user=True)\n",
    "\n",
    "    #tokenize question and run on model with text\n",
    "    elif command.endswith('?'):\n",
    "        question = tokenize(command)\n",
    "\n",
    "        vocab = set()\n",
    "        vocab |= set(text + question)\n",
    "        vocab = sorted(vocab)\n",
    "\n",
    "        word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "\n",
    "        story_vector, query_vector = vectorize_ques([(text, question)], word_idx, max_story_len, max_query_len)\n",
    "        prediction = model.predict([story_vector, query_vector])\n",
    "        print(prediction)\n",
    "        if prediction < 0.5:\n",
    "            response = \"No \" + str(prediction)\n",
    "        else:\n",
    "            response = \"Yes \" + str(prediction)\n",
    "        \n",
    "        slack_client.api_call(\"chat.postMessage\", channel=channel, text=response, as_user=True)\n",
    "\n",
    "    #tokenize input and add to text\n",
    "    elif command != '':\n",
    "        if not command.endswith('.'):\n",
    "            command += '.'\n",
    "        text.extend(tokenize(command))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def parse_slack_output(slack_rtm_output):\n",
    "    \"\"\"\n",
    "        The Slack Real Time Messaging API is an events firehose.\n",
    "        this parsing function returns None unless a message is\n",
    "        directed at the Bot, based on its ID.\n",
    "    \"\"\"\n",
    "    output_list = slack_rtm_output\n",
    "    if output_list and len(output_list) > 0:\n",
    "        for output in output_list:\n",
    "            if output and 'text' in output and AT_BOT in output['text']:\n",
    "                # return text after the @ mention, whitespace removed\n",
    "                return output['text'].split(AT_BOT)[1].strip(), \\\n",
    "                       output['channel']\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bAbIbot connected and running!\n",
      "command: Mary got milk there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: John moved to the bedroom.\n",
      "command: Is John in the bedroom?\n",
      "[[ 0.08649782]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    READ_WEBSOCKET_DELAY = 1 # 1 second delay between reading from firehose\n",
    "    if slack_client.rtm_connect():\n",
    "        print(\"bAbIbot connected and running!\")\n",
    "        while True:\n",
    "            command, channel = parse_slack_output(slack_client.rtm_read())\n",
    "            if channel:\n",
    "                handle_command(command, channel)\n",
    "            time.sleep(READ_WEBSOCKET_DELAY)\n",
    "    else:\n",
    "        print(\"Connection failed. Invalid Slack token or bot ID?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
